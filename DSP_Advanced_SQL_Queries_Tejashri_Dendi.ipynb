{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        
        "\n",
        "<h2 align=\"center\">\n",
        "    Project: Advanced SQL Queries - #3\n",
        "</h2>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tt70feOIfcQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Description:**\n",
        "\n",
        "To work with the New York City Airbnb dataset in this project, we need to create and connect to an SQLite database as seen in the steps within this notebook.\n",
        "\n",
        "\n",
        "\n",
        "**Dataset**\n",
        "- You can find the New York City Airbnb dataset on Kaggle: [New York City Airbnb Dataset](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data)\n"
      ],
      "metadata": {
        "id": "35fgH_hXgAUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "This SQL project  uses a real-world dataset. In this project, we will work with the New York City Airbnb dataset and performadvance data analysis tasks.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Libraries and Database Setup](#database-setup)\n",
        "2. [Loading the Dataset](#loading-dataset)\n",
        "3. [Advanced SQL Queries](#sql-queries)\n",
        "4. [Closing Connection](#closing-connection)\n",
        "5. [Summary of Advanced SQL Commands](#summary-commands)\n",
        "\n",
        "# Section 1: Libraries and Database Setup <a name=\"database-setup\"></a>\n",
        "\n",
        "###  1.1: Import Libraries\n",
        "Let's start by importing the necessary libraries.\n"
      ],
      "metadata": {
        "id": "I4xHzjkqigQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "!pip install -q kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuwWeEnIiirc",
        "outputId": "8578a986-4056-4a42-87e8-7772ac7e6084"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Olk6vQ34FHAI",
        "outputId": "f8403ac5-3886-432e-e915-62a594f93130"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35f4579c-9639-4c17-80b4-5ab28e920f28\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35f4579c-9639-4c17-80b4-5ab28e920f28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dgomonov/new-york-city-airbnb-open-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWdyLxKeFMdv",
        "outputId": "d1b8b41f-b5ca-449b-e45f-0d0c3919480d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data\n",
            "License(s): CC0-1.0\n",
            "Downloading new-york-city-airbnb-open-data.zip to /content\n",
            " 82% 2.00M/2.44M [00:00<00:00, 2.97MB/s]\n",
            "100% 2.44M/2.44M [00:00<00:00, 3.07MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/new-york-city-airbnb-open-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqGrFYZyFYGW",
        "outputId": "b0ab2d79-db9d-49f0-a4ce-9e0ab278b0f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/new-york-city-airbnb-open-data.zip\n",
            "  inflating: AB_NYC_2019.csv         \n",
            "  inflating: New_York_City_.png      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3"
      ],
      "metadata": {
        "id": "NnR6oXHNG6Ff"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  1.2: Connect to the Database\n",
        "\n",
        "Next, establish a connection to the SQLite database named 'airbnb.db'.\n",
        "Use the sqlite3 library to create a connection object and store it in a variable called 'conn'.\n"
      ],
      "metadata": {
        "id": "qSERoLykixcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('airbnb.db')\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "8G9tDLd2iyq7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Loading the Dataset <a name=\"loading-dataset\"></a>"
      ],
      "metadata": {
        "id": "gCE_OEk5BrF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  2.1: Load the Dataset\n",
        "- We will work with the 'listings' table from the New York City Airbnb dataset.\n",
        "- Load the dataset from the CSV file 'AB_NYC_2019.csv' into a DataFrame named 'df'.\n",
        "- Then, import the DataFrame into the 'listings' table in the database using the to_sql() method.\n",
        "\n",
        "\\\\\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_bXjXLHli0aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the dataset into the SQLite database\n",
        "data_path = '/content/AB_NYC_2019.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df.to_sql('listings', conn, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "blwNI_PEi5FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e98d15-9189-439e-a4f2-29d6897fcf6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48895"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Advanced SQL Tasks <a name=\"sql-queries\"></a>\n",
        "\n",
        "Query the database: Write SQL queries to analyze the data in the SQLite database and can use the sqlite3 library to execute the queries and fetch the results."
      ],
      "metadata": {
        "id": "1j3xgaK4Ck3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.1: Analyzing Host Performance\n",
        "- Find the top 10 hosts with the highest average ratings.\n",
        "- Include host's name, number of reviews, and average rating."
      ],
      "metadata": {
        "id": "eKaLdB8Fi7Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- 1. Calculate the number of reviews received by each host and name the result as 'num_reviews'\n",
        "\n",
        "SELECT host_name, COUNT(*) AS num_reviews, AVG(CAST(number_of_reviews AS FLOAT)) AS avg_rating FROM listings\n",
        "-- 2. Calculate the average rating (reviews per month) for each host and name the result as 'avg_rating'\n",
        "-- 3. Group the results by host name\n",
        "Group By host_name\n",
        "-- 4. Order the results by average rating in descending order\n",
        "ORDER BY avg_rating DESC\n",
        "-- 5. Display the top 10 hosts with their names, the number of reviews, and average rating\n",
        "LIMIT 10;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gqe3KmtUCr9V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result = pd.read_sql_query(query, conn)\n",
        "print(\"\\nAnalyzing Host Performance:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fib2hIqjKWr",
        "outputId": "55943c5d-432d-49c8-d5ea-b927e9a73d60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing Host Performance:\n",
            "        host_name  num_reviews  avg_rating\n",
            "0            Dona            2       602.5\n",
            "1             Asa            1       488.0\n",
            "2  Dennis & Naoko            1       441.0\n",
            "3         Miss Dy            1       434.0\n",
            "4        Shunichi            1       430.0\n",
            "5    Gladys & Bob            1       414.0\n",
            "6             Sne            1       396.0\n",
            "7          Malini            1       392.0\n",
            "8            Amia            1       385.0\n",
            "9            J. E            1       378.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.2: Analyzing Monthly Price Trends\n",
        "- Display the month, average price, and number of listings for each month."
      ],
      "metadata": {
        "id": "0O4Nfb9yC61D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- 1. Use the `strftime('%m', last_review)` function to extract the month from the 'last_review' column and name it as 'month'\n",
        "-- 2. Calculate the average price for listings in each month and name the result as 'avg_price'\n",
        "SELECT strftime('%m', last_review) AS month, AVG(CAST(price AS FLOAT)) AS avg_price, COUNT(*) AS num_listings FROM listings\n",
        "-- 3. Group the results by the 'month' column\n",
        "-- 3. Calculate the number of listings in each month and name the result as 'num_listings'\n",
        "\n",
        "-- 4. Group the results by the 'month' column\n",
        "Group By month\n",
        "-- 5. Order the results by average price in descending order\n",
        "ORDER BY avg_price DESC;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4fJa4Bt6C7Nw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result = pd.read_sql_query(query, conn)\n",
        "print(\"Analyzing Monthly Price Trends:\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "_KICYQII-AVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88042b3-c260-481d-b692-b022ab4d4935"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing Monthly Price Trends:\n",
            "   month   avg_price  num_listings\n",
            "0   None  192.919021         10052\n",
            "1     12  160.796610          1770\n",
            "2     02  155.716883           770\n",
            "3     01  150.478904          2773\n",
            "4     09  149.494463          1535\n",
            "5     07  142.290382          5937\n",
            "6     10  142.065330          1546\n",
            "7     06  140.769667         13589\n",
            "8     04  139.504979          2109\n",
            "9     11  138.532815          1158\n",
            "10    05  137.909594          4701\n",
            "11    03  136.836957          1288\n",
            "12    08  132.133173          1667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.3: Find the top 5 neighborhoods with the highest price variability\n",
        "-  Find the top 5 neighborhoods with the highest price variability.\n",
        "-  Display neighborhood and price variability.\n"
      ],
      "metadata": {
        "id": "uULLKoO0DEou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- 1. Create a Common Table Expression (CTE) named 'price_variability' that calculates the following for each neighborhood:\n",
        "--    - Calculate the average price and name it as 'avg_price'\n",
        "--    - Calculate the maximum price and name it as 'max_price'\n",
        "--    - Calculate the minimum price and name it as 'min_price'\n",
        "WITH price_variability AS (\n",
        "    SELECT neighbourhood, AVG(CAST(price AS FLOAT)) AS avg_price, MAX(CAST(price AS FLOAT)) AS max_price, MIN(CAST(price AS FLOAT)) AS min_price\n",
        "    FROM listings\n",
        "    GROUP BY neighbourhood\n",
        ")\n",
        "-- 2. In the main query, select the 'neighbourhood' column and calculate the price variability as the difference between 'max_price' and 'min_price'\n",
        "SELECT neighbourhood, max_price - min_price AS price_variability FROM price_variability\n",
        "-- 3. Order the results by price variability in descending order\n",
        "ORDER BY price_variability DESC\n",
        "-- 4. Limit the results to the top 5 neighborhoods\n",
        "LIMIT 5;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EDnyQuz1DDin"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result = pd.read_sql_query(query, conn)\n",
        "print(\"Advanced Aggregation:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGIUx6pn1ZpM",
        "outputId": "112548a6-eb11-46e4-89f3-329538e53920"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Advanced Aggregation:\n",
            "     neighbourhood  price_variability\n",
            "0       Greenpoint            10000.0\n",
            "1  Upper West Side             9990.0\n",
            "2          Astoria             9975.0\n",
            "3  Lower East Side             9970.0\n",
            "4      East Harlem             9969.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.4: Advanced Data Manipulation\n",
        "- Calculate days since the last review and identify top 10 listings.\n",
        "- Display listing ID, name, and days since the last review."
      ],
      "metadata": {
        "id": "yPvuIfq7DMhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- 1. Select the following columns from the 'listings' table:\n",
        "--    - 'id'\n",
        "--    - 'name'\n",
        "--    - Calculate the number of days since the last review and name it as 'days_since_last_review.'\n",
        "--      Use the 'julianday' function to calculate the difference in days between the current date and the 'last_review' date\n",
        "SELECT id, name, julianday('now') - julianday(last_review) AS days_since_last_review FROM listings\n",
        "-- 2. Order the results by 'days_since_last_review' in descending order\n",
        "ORDER BY days_since_last_review DESC\n",
        "-- 3. Limit the results to the top 10 listings\n",
        "LIMIT 10;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "U1r32q1rDOil"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result = pd.read_sql_query(query, conn)\n",
        "print(\"\\nAdvanced Data Manipulation:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s93h67wkDR6r",
        "outputId": "a25f99ce-6e20-475d-9eb9-a717dcdcb270"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advanced Data Manipulation:\n",
            "       id                                               name  \\\n",
            "0   74860  Sunlit and Cozy Williamsburg/Greenpoint, Brooklyn   \n",
            "1   40039                 Luxurious Condo in DUBMO with View   \n",
            "2   81739                  Loft w/ Terrace @ Box House Hotel   \n",
            "3   28396                  Modern Apt with Spectacular Views   \n",
            "4   32363                 Fully Furnished Basement Apartment   \n",
            "5   27883                             East Village Sanctuary   \n",
            "6    7801                   Sweet and Spacious Brooklyn Loft   \n",
            "7  229874                     Oversized Studio in Park Slope   \n",
            "8   98330                LOVELY APARTMENT IN THE HEART OF NY   \n",
            "9  464231                     Large Room w/ Private Entrance   \n",
            "\n",
            "   days_since_last_review  \n",
            "0             4875.792212  \n",
            "1             4847.792212  \n",
            "2             4830.792212  \n",
            "3             4701.792212  \n",
            "4             4700.792212  \n",
            "5             4618.792212  \n",
            "6             4600.792212  \n",
            "7             4595.792212  \n",
            "8             4594.792212  \n",
            "9             4447.792212  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.5:  Identifying Top Hosts by Revenue\n",
        "- Calculate the total revenue generated by each host and rank them based on revenue.\n",
        "- Display the host name, total revenue, and their rank."
      ],
      "metadata": {
        "id": "nIWy051Y2j7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- 1. Select the following columns from the 'listings' table:\n",
        "--    - 'host_name'\n",
        "--    - Calculate the total revenue for each host by multiplying 'price' by 'minimum_nights' and name it as 'total_revenue.'\n",
        "--    - Use the RANK() window function to determine the rank of each host by total revenue in descending order and name it as 'revenue_rank.'\n",
        "SELECT host_name, SUM(CAST(price AS FLOAT) * minimum_nights) AS total_revenue, RANK() OVER (ORDER BY SUM(CAST(price AS FLOAT) * minimum_nights) DESC) AS revenue_rank FROM listings\n",
        "-- 2. Group the results by 'host_name.'\n",
        "GROUP BY host_name\n",
        "-- 3. Order the results by 'total_revenue' in descending order.\n",
        "ORDER BY total_revenue DESC\n",
        "-- 4. Limit the results to the top 10 hosts.\n",
        "LIMIT 10;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gygsx68g2YEX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result = pd.read_sql_query(query, conn)\n",
        "print(\"Identifying Top Hosts by Revenue:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOZr1Ty02YHk",
        "outputId": "cbb05f03-89b5-45b1-9468-1db4b9882d71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identifying Top Hosts by Revenue:\n",
            "      host_name  total_revenue  revenue_rank\n",
            "0    Blueground      2258580.0             1\n",
            "1         Jenny      1215111.0             2\n",
            "2          Kara      1172637.0             3\n",
            "3           Amy      1153867.0             4\n",
            "4      Kathrine      1002082.0             5\n",
            "5  Sonder (NYC)       950453.0             6\n",
            "6         Iveta       857750.0             7\n",
            "7        Noelle       732930.0             8\n",
            "8       Pranjal       664320.0             9\n",
            "9       Michael       610539.0            10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Closing the Database Connection <a name=\"closing-connection\"></a>"
      ],
      "metadata": {
        "id": "CyaxVtAuDyDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  4.1: Close the Cursor and Database Connection\n",
        "- It's good practice to close the cursor and the database connection when you're done working with the database to free up system resources and maintain proper connection management.\n"
      ],
      "metadata": {
        "id": "nFKyd0DbD4Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Make sure to include these lines of code at the end of your script to properly close the cursor and database connection.\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "_z_H6ZsmD2GX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Summary of Advanced SQL Commands <a name=\"summary-commands\"></a>"
      ],
      "metadata": {
        "id": "5tOYpl9rVXV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Below is a summary of the advanced SQL commands used:\n",
        "\n",
        "** 1.2: Connect to the Database**\n",
        "- Established a connection to the SQLite database.\n",
        "\n",
        "** 2.1: Load the Dataset**\n",
        "- Loaded the dataset into a DataFrame.\n",
        "- Imported the DataFrame into the database.\n",
        "\n",
        "** 3.1: Identifying Top Hosts by Reviews and Ratings**\n",
        "- SQL Commands: SELECT, COUNT(), AVG(), GROUP BY, ORDER BY, LIMIT\n",
        "- Description: Calculate the number of reviews and average ratings for each host and identify the top hosts by ratings and reviews.\n",
        "\n",
        "** 3.2: Analyzing Seasonal Price Trends**\n",
        "- SQL Commands: SELECT, strftime(), AVG(), COUNT(), GROUP BY, ORDER BY\n",
        "- Description: Analyze seasonal price trends by extracting the month from the last review date and calculating average prices.\n",
        "\n",
        "** 3.3: Finding Neighborhoods with Price Variability**\n",
        "- SQL Commands: WITH, SELECT, AVG(), MAX(), MIN(), GROUP BY, ORDER BY\n",
        "- Description: Identify neighborhoods with the highest price variability by calculating the difference between the maximum and minimum prices.\n",
        "\n",
        "** 3.4: Advanced Data Manipulation**\n",
        "- SQL Commands: SELECT, julianday(), ORDER BY, LIMIT\n",
        "- Description: Calculate the number of days since the last review for each listing and sort them by the days since the last review.\n",
        "\n",
        "** 3.5: Identifying Top Hosts by Revenue**\n",
        "- SQL Commands: SELECT, SUM(), RANK(), GROUP BY, ORDER BY, LIMIT\n",
        "- Description: Determine the top hosts by total revenue generated from their listings, including a ranking based on revenue.\n",
        "\n",
        "** 4.1: Close the Cursor and Database Connection**\n",
        "- Closed the cursor and the database connection.\n",
        "\n",
        "This summary provides an overview of the advanced SQL commands used in this project for data analysis tasks."
      ],
      "metadata": {
        "id": "wS_xxvBKVTha"
      }
    }
  ]
}
